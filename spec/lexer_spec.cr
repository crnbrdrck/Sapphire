require "./spec_helper"

# Unlike how the interpreter book works, we're going to be using files from the start
# These files are going to be stored in `<project>/examples/*.drzl`
describe Drizzle::Lexer do
  it "correctly creates Token instances for all single character tokens in Drizzle" do
    # Lexer also handles strings. This is for REPL and such. This might change later.
    input = "=+(){},:"
    file_name = "<stdin>"

    # Generate an array of tokens that are expected to be generated by the Lexer
    expected_tokens = [
      Drizzle::Token.new(Drizzle::TokenType::ASSIGN, "=", file_name, 1, 1),
      Drizzle::Token.new(Drizzle::TokenType::PLUS, "+", file_name, 1, 2),
      Drizzle::Token.new(Drizzle::TokenType::LEFT_PAREN, "(", file_name, 1, 3),
      Drizzle::Token.new(Drizzle::TokenType::RIGHT_PAREN, ")", file_name, 1, 4),
      Drizzle::Token.new(Drizzle::TokenType::LEFT_BRACE, "{", file_name, 1, 5),
      Drizzle::Token.new(Drizzle::TokenType::RIGHT_BRACE, "}", file_name, 1, 6),
      Drizzle::Token.new(Drizzle::TokenType::COMMA, ",", file_name, 1, 7),
      Drizzle::Token.new(Drizzle::TokenType::COLON, ":", file_name, 1, 8),
      Drizzle::Token.new(Drizzle::TokenType::EOF, Char::ZERO.to_s, file_name, 2, 1),
    ]

    # Create a lexer for this file
    lexer = Drizzle::Lexer.new input

    # Loop through the expected_tokens array and ensure that the tokens match the lexer output
    expected_tokens.each do |expected|
      received = lexer.get_next_token
      received.token_type.should eq expected.token_type
      received.literal.should eq expected.literal
      received.file_name.should eq expected.file_name
      received.line_num.should eq expected.line_num
      received.char_num.should eq expected.char_num
    end
  end

  it "correctly creates Token instances given the `example1.drzl` script as input" do
    file_name = "examples/example1.drzl"
    input_file = File.open file_name

    # Generate an array of expected Tokens
    expected_tokens = [
      # let five: int = 5
      Drizzle::Token.new(Drizzle::TokenType::LET, "let", file_name, 1, 1),
      Drizzle::Token.new(Drizzle::TokenType::IDENTIFIER, "five", file_name, 1, 5),
      Drizzle::Token.new(Drizzle::TokenType::COLON, ":", file_name, 1, 9),
      Drizzle::Token.new(Drizzle::TokenType::IDENTIFIER, "int", file_name, 1, 11),
      Drizzle::Token.new(Drizzle::TokenType::ASSIGN, "=", file_name, 1, 15),
      Drizzle::Token.new(Drizzle::TokenType::INTEGER, "5", file_name, 1, 17),

      # let ten: int = 10
      Drizzle::Token.new(Drizzle::TokenType::LET, "let", file_name, 2, 1),
      Drizzle::Token.new(Drizzle::TokenType::IDENTIFIER, "ten", file_name, 2, 5),
      Drizzle::Token.new(Drizzle::TokenType::COLON, ":", file_name, 2, 8),
      Drizzle::Token.new(Drizzle::TokenType::IDENTIFIER, "int", file_name, 2, 10),
      Drizzle::Token.new(Drizzle::TokenType::ASSIGN, "=", file_name, 2, 14),
      Drizzle::Token.new(Drizzle::TokenType::INTEGER, "10", file_name, 2, 16),

      # def add(x: num, y: num) -> num {
      Drizzle::Token.new(Drizzle::TokenType::FUNCTION, "def", file_name, 4, 1),
      Drizzle::Token.new(Drizzle::TokenType::IDENTIFIER, "add", file_name, 4, 5),
      Drizzle::Token.new(Drizzle::TokenType::LEFT_PAREN, "(", file_name, 4, 8),
      Drizzle::Token.new(Drizzle::TokenType::IDENTIFIER, "x", file_name, 4, 9),
      Drizzle::Token.new(Drizzle::TokenType::COLON, ":", file_name, 4, 10),
      Drizzle::Token.new(Drizzle::TokenType::IDENTIFIER, "num", file_name, 4, 12),
      Drizzle::Token.new(Drizzle::TokenType::COMMA, ",", file_name, 4, 15),
      Drizzle::Token.new(Drizzle::TokenType::IDENTIFIER, "y", file_name, 4, 17),
      Drizzle::Token.new(Drizzle::TokenType::COLON, ":", file_name, 4, 18),
      Drizzle::Token.new(Drizzle::TokenType::IDENTIFIER, "num", file_name, 4, 20),
      Drizzle::Token.new(Drizzle::TokenType::RIGHT_PAREN, ")", file_name, 4, 23),
      Drizzle::Token.new(Drizzle::TokenType::RETURN_TYPE, "->", file_name, 4, 25),
      Drizzle::Token.new(Drizzle::TokenType::IDENTIFIER, "num", file_name, 4, 28),
      Drizzle::Token.new(Drizzle::TokenType::LEFT_BRACE, "{", file_name, 4, 32),

      # return x + y
      Drizzle::Token.new(Drizzle::TokenType::RETURN, "return", file_name, 5, 5),
      Drizzle::Token.new(Drizzle::TokenType::IDENTIFIER, "x", file_name, 5, 12),
      Drizzle::Token.new(Drizzle::TokenType::PLUS, "+", file_name, 5, 14),
      Drizzle::Token.new(Drizzle::TokenType::IDENTIFIER, "y", file_name, 5, 16),

      # }
      Drizzle::Token.new(Drizzle::TokenType::RIGHT_BRACE, "}", file_name, 6, 1),

      # let result: num = add(five, ten)
      Drizzle::Token.new(Drizzle::TokenType::LET, "let", file_name, 8, 1),
      Drizzle::Token.new(Drizzle::TokenType::IDENTIFIER, "result", file_name, 8, 5),
      Drizzle::Token.new(Drizzle::TokenType::COLON, ":", file_name, 8, 11),
      Drizzle::Token.new(Drizzle::TokenType::IDENTIFIER, "num", file_name, 8, 13),
      Drizzle::Token.new(Drizzle::TokenType::ASSIGN, "=", file_name, 8, 17),
      Drizzle::Token.new(Drizzle::TokenType::IDENTIFIER, "add", file_name, 8, 19),
      Drizzle::Token.new(Drizzle::TokenType::LEFT_PAREN, "(", file_name, 8, 22),
      Drizzle::Token.new(Drizzle::TokenType::IDENTIFIER, "five", file_name, 8, 23),
      Drizzle::Token.new(Drizzle::TokenType::COMMA, ",", file_name, 8, 27),
      Drizzle::Token.new(Drizzle::TokenType::IDENTIFIER, "ten", file_name, 8, 29),
      Drizzle::Token.new(Drizzle::TokenType::RIGHT_PAREN, ")", file_name, 8, 32),

      # EOF
      Drizzle::Token.new(Drizzle::TokenType::EOF, Char::ZERO.to_s, file_name, 9, 1),
    ]

    # Create a lexer for this file
    lexer = Drizzle::Lexer.new input_file
    # Loop through the expected_tokens array and ensure that the tokens match the lexer output
    expected_tokens.each do |expected|
      received = lexer.get_next_token
      received.token_type.should eq expected.token_type
      received.literal.should eq expected.literal
      received.file_name.should eq expected.file_name
      received.line_num.should eq expected.line_num
      received.char_num.should eq expected.char_num
    end
  end
end
